---
title: "ProjectPdf_Fixed"
author: "Tali"
date: "12/25/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align="center", out.width = '65%',
                      message=FALSE, warning=FALSE)
```

# MovieLens Project # 

## Data Preperation

### 1. installing required packeges

```{r required packeges, eval=FALSE, include=FALSE}
if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")
if(!require(lubridate)) install.packages("lubridate", repos = "http://cran.us.r-project.org")
if(!require(scales)) install.packages("scales", repos = "http://cran.us.r-project.org")
if(!require(gridExtra)) install.packages("gridExtra", repos = "http://cran.us.r-project.org")
if(!require(knitr)) install.packages("knitr", repos = "http://cran.us.r-project.org")
if(!require(DescTools)) install.packages("DescTools", repos = "http://cran.us.r-project.org")
if(!require(colorspace)) install.packages("colorspace", repos = "http://cran.us.r-project.org")
if(!require(cowplot)) install.packages("cowplot", repos = "http://cran.us.r-project.org")
```

```{r install required packeges, echo=TRUE}
library(tidyverse)
library(caret)
library(data.table)
library(lubridate)
library(scales)
library(gridExtra)
library(knitr)
library(DescTools) 
library(colorspace)
library(cowplot)
library(formattable)
```

### 2. Loading Movielens Dataset

```{r Loading Movielens Dataset, echo=TRUE}
# MovieLens 10M dataset:
# https://grouplens.org/datasets/movielens/10m/
# http://files.grouplens.org/datasets/movielens/ml-10m.zip

### 3.Create Edx set (training set) and Validation Sets (final hold-out test set)

#### Use a shortcut to load the data from local computer
load("D:/OneDrive/Documents/Tali/Tali data science studies/movielens_dataset/movielens_dataset_fixed.RData")
####

#dl <- tempfile()
#download.file("http://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)

#ratings <- fread(text = gsub("::", "\t", readLines(unzip(dl, "ml-10M100K/ratings.dat"))),
#                 col.names = c("userId", "movieId", "rating", "timestamp"))

#movies <- str_split_fixed(readLines(unzip(dl, "ml-10M100K/movies.dat")), "\\::", 3)
#colnames(movies) <- c("movieId", "title", "genres")

# if using R 3.6 or earlier:
#movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(levels(movieId))[movieId],
#                                          title = as.character(title),
#                                         genres = as.character(genres))

#movielens <- left_join(ratings, movies, by = "movieId")

# Validation set will be 10% of MovieLens data
#set.seed(1, sample.kind="Rounding") # if using R 3.5 or earlier, use `set.seed(1)`
#test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)
#edx <- movielens[-test_index,]
#temp <- movielens[test_index,]

# Make sure userId and movieId in validation set are also in edx set
#validation <- temp %>% 
#  semi_join(edx, by = "movieId") %>%
#  semi_join(edx, by = "userId")

# Add rows removed from validation set back into edx set
#removed <- anti_join(temp, validation)
#edx <- rbind(edx, removed)

#rm(dl, ratings, movies, test_index, temp, movielens, removed)
```

#### Get A Glimpse Of Edx Data 
```{r glimpse Of edx, echo=FALSE}
glimpse(edx)
```
'edx' data set contains 6 columns; 

1. userId - Unique ID for the user

2. movieId - Unique ID for the movie

3. rating - A rating between 0.5 and 5 for the movie

4. timestamp - Date and time the rating was given

5. title - Movie title and year the movie was released.

6. genres - Genres associated with the movie

And 9 million rows. Each row provides a given rating to one movie by specific user. 

### 4. Sanitizing the data - timestamp column
The date-time in the 'edx' timestamp column is a point on the timeline, stored as the number of seconds since 1970-01-01 00:00:00 UTC.

In order to be able to use the time information and for better convenience, I converted the timestamp into rate date, added rate year column, extracted the release year from the movie title and deleted the release year from movie title
```{r sanitizing the data, echo=TRUE}
#edx_year_sanitized <- edx %>% 
#  mutate(rate_year = year(as_datetime(timestamp)),
#          rate_date = date(as_datetime(timestamp)),
#          release_year =as.numeric(str_extract(title, "(?<=\\()(\\d{4})(?=\\))")),
#          title= str_remove(as.character(title),"(\\(\\d{4}\\))")) %>% 
#  select(-timestamp)
```

Get a glimpse of the sanitized data 
```{r glimpse of the sanitized data, echo=FALSE}
glimpse(edx_year_sanitized)
```

### 5. The Dataset Overview
```{r summarized edx_year_sanitized data, echo=FALSE}
edx_year_sanitized %>% 
  summarize("Number of users" = n_distinct(userId),
            "Number of movies" = n_distinct(movieId), 
            "Number of ratings (M)" = nrow(edx)/1000000,
            "Number of 'missing' ratings (M)"=
              ((n_distinct(userId)*n_distinct(movieId))-nrow(edx))/1000000) %>%
  knitr::kable()
```
'edx_year_sanitized' contains about 70k different users that provided ratings and about 11k different rated movies.

The following matrix contain random sample of 120 movies and 120 users. 

If we were to look at the entire matrix, the empty cells (about 737 million cells in the data set overall), represent the unrated movies by all users. 
Users rated only the selected movies by their personal preferences, therefore we have "only" 9 million ratings. 

Each of the colored cells represent one rating and the color varies according to its score. 
```{r preview matrix, echo=FALSE}
# figure 1 # 
users <- sample(unique(edx_year_sanitized$userId), 120)
edx_year_sanitized %>% 
  filter(userId %in% users) %>% 
  select(userId, movieId, rating) %>%
  spread(movieId, rating) %>% 
  select(sample(ncol(.), 120)) %>% 
  as.matrix() %>% 
  t(.) %>%
  image(1:120, 1:120,. , xlab="Movies", ylab="Users")
abline(h=0:120+0.5, v=0:120+0.5, col = "whitesmoke")
title("User / Movie Rating Combination")
```

### Evaluate the movie - Rating Score
```{r rating score summarize, echo=FALSE}
# rating score - mean, median, mode
edx_year_sanitized %>% 
  summarize(mean=mean(rating),
            median=median(rating),
            mode=Mode(rating))%>% 
  knitr::kable()
```
The average rate score is 3.512 stars while both median and mode rate score is 4 stars (distribution is negatively skewed).

About 2.5 milion ratings, which is 29 percent of the total ratings, are 4 stars and only 41 percent of the ratings is 3 stars and less.

In general, whole star ratings are more common than half star ratings, and are 79.5 percent of the total ratings, as shown in the next plot. 
```{r graph rating score distribution, echo=FALSE}
# figure 2 # 
data.frame(edx_year_sanitized$rating, 
stars=ifelse(floor(edx_year_sanitized$rating)==edx_year_sanitized$rating,
             "whole_star","half_star"))%>% 
group_by(edx_year_sanitized.rating, stars) %>% 
summarize(count=n()) %>% 
ggplot(aes(x=edx_year_sanitized.rating,y=(count/sum(count)),fill = stars))+
geom_bar(stat='identity') +
scale_x_continuous(breaks=seq(0.5, 5, by= 0.5)) +
scale_y_continuous(labels=percent)+
scale_fill_manual(values = c("half_star"="lightskyblue", "whole_star"="blue")) +
geom_vline(xintercept=mean(edx_year_sanitized$rating) ,color="black", linetype="dashed", size=0.5)+
geom_vline(xintercept=median(edx_year_sanitized$rating) ,color="red", linetype="dashed", size=0.5)+
labs(x="Stars Rating", y="Ratings Percentage") +
ggtitle("Stars Ratings Percentage")
``` 

Top 15 blockbuster movies
```{r graph blockbuster movies, echo=FALSE}
# figure 3 # 
edx_year_sanitized %>% 
  group_by(title) %>%
  summarize(count_k=n()/1000, avg=mean(rating)) %>% # count in thousands
  top_n(15,count_k)%>%
  ggplot(aes(avg,count_k,lable=title)) +
  geom_point()+
  geom_text(aes(label=title), size=3,  hjust=0,vjust=0)+
  xlim(3,5)+
  ggtitle("Top 15 blockbuster movies")+
  labs(x="Rating Score", y="Total Number Of Ratings(Thousands)")
```
The plot above demonstrates the top 15 blockbuster movies with overall number of ratings higher than 22k, most of them are rated above the average score.

The top leader is Pulp Fiction, directed by Quentin Tarantino, and was released on 1994.

###The challenge of recommendation systems
Since our goal is to predict the future ratings, we can treat this as a machine learning challenge and "fill" the empty cells from the above matrix.

From the user's prespective, we'll want to fit a rating which is as close as possible to the actual rating the user would have rated the movie, and use that for future users with similiar preferences outside of our control.

From the movie's prespective, we'll want to predict if the movie could become a blockbuster, or less than that.

We'll use the following features: UserId, MovieId, Age of the movie at rating, time (release year) and genre.

### 6. Create additional partition of training and test set 
In this step, we'll create additional training and test sets, in order to evaluate the accuracy of the models we build and to prevent overfitting of the RMSE.

Once we hit RMSE < 0.8649, we'll use the final holdout test set (validation) and determine the final model RMSE.
```{r additional partition}
set.seed(755, sample.kind="Rounding") # if using R 3.5 or earlier, use `set.seed(755)`

# randomly splitting edx data set into 80% training set and 20% testing set 
test_index <- createDataPartition(y = edx_year_sanitized$rating, times = 1,
                                  p = 0.2, list = FALSE)
train_edx <- edx_year_sanitized %>% slice(-test_index)
temp <- edx_year_sanitized %>% slice(test_index)

# making sure that the test set includes users and movies that appear in the training set.  
test_edx <- temp %>% 
  semi_join(train_edx, by = "movieId") %>%
  semi_join(train_edx, by = "userId")
removed <- anti_join(temp,test_edx)
train_edx <- rbind(train_edx, removed)
rm(temp, removed)
```

### 7.RMSE function

```{r RMSE function}
RMSE <- function(true_ratings, predicted_ratings){
        sqrt(mean((true_ratings - predicted_ratings)^2))
} 
```

####  A. naive model 


```{r mu hat}
mu_hat <- mean(train_edx$rating)
mu_hat
```

if we predict all unknown ratings with mu we obtain the following RMSE 
```{r naive_rmse}
naive_rmse <- RMSE(test_edx$rating, mu_hat)
naive_mse <- MSE(test_edx$rating, mu_hat)

#creating results table with naive approach
naive_model_results <- tibble(method = "Average only",MSE=naive_mse, RMSE = naive_rmse)
naive_model_results
```
The RMSE we got is 1.06, which means our typical error is larger than one star, which is not good enough! 
To remind ourselves, the goal is to aspire for RMSE < 0.8649 

### 7. userId 

#### User Activity
```{r users summarize, echo=FALSE}
train_edx %>%  
  group_by(userId) %>% 
  summarize(count=n()) %>% 
  summarize(mean=round(mean(count)), 
            median=median(count), 
            mode=Mode(count,na.rm=FALSE), 
            min=min(count), max=max(count)) %>%
  knitr::kable()
```
Each of the 70K different usesrs rated in average 103 different movies. The most frequent value of ratings is only 17 movies, but there are 3% of users who rated more than 500 movies! 
The distribution is positively skewed, as the mean is larger than the mode and median.

Both plots demonstrates extreme observations (outliers) e.g. very low or high number of ratings, which indicates that some users are more active than others at rating movies.

Outliers affect RMSE which is highly sensitive to them, and therefore we will have to treat this and set penalty term going forward.

```{r number of rating dist, echo=FALSE}
#graph number of rating dist. by number of users 
# figure 5 # 
user_hist <- 
  train_edx %>% 
  group_by(userId) %>%
  summarize(count=n()) %>% 
  ggplot(aes(count)) +
  geom_histogram(bins = 30, color = "gray20")+ 
  geom_vline(aes(xintercept=median(count),color="median"), 
                 linetype="dashed", size=0.5)+
  geom_vline(aes(xintercept=Mode(count, na.rm = FALSE),color="Mode"), 
                 linetype="dashed", size=0.5)+
  geom_vline(aes(xintercept=mean(count),color="mean"), 
                 linetype="dashed", size=0.5)+
  scale_color_manual(name = "Statistics", 
                     values = c(median = "skyblue1", mean = "pink1",Mode="blue"))+
  scale_x_log10()+
  ggtitle("User Distribution")+ 
  labs(x="Number of Ratings Count", y="Number of Users") 

#graph number of ratings per user, see extreme observation  
# figure 6 # 
rate_p_u<- 
  train_edx %>% 
  group_by(userId) %>%
  summarize(count=n()) %>% 
  ggplot(aes(userId,count)) +
  geom_point(alpha=0.1)+
  geom_hline(aes(yintercept=mean(count)),color="pink1", 
                 linetype="dashed", size=0.5)+
  geom_hline(aes(yintercept=Mode(count, na.rm = FALSE)),color="blue",
                 linetype="dashed", size=0.5)+
  geom_hline(aes(yintercept=median(count)),color="skyblue1", 
                 linetype="dashed", size=0.5)+
  ggtitle("Total Number Of Ratings Per user")+ 
  labs(x="userId - 69,878 Unique Users", y="Total Ratings Per User")

#plot 2 graphs - place multiple grobs on a page 
grid.arrange(rate_p_u, user_hist, ncol=2)
```
50% of the ratints are between 3 to 4 stars. Some users love every movie they watch and simply rate most of them 5 stars, but the left tail inidicate users that are very critic and rate lot of 1-2 stars. 

```{r user rating score dist, echo=FALSE}
# figure 7 # 
train_edx %>% 
  group_by(userId) %>% 
  summarise(rating_score=mean(rating)) %>% 
  ggplot(aes(rating_score))+
  geom_histogram(bins=30, color="black")+
  geom_vline(aes(xintercept=mean(train_edx$rating)),color="red",
                 linetype="dashed", size=0.5)+
  ggtitle("Rating score dist. by number of users")+ 
  labs(x="Rating score", y="number of users")
```

####  B. first model - modeling user effect


```{r mu}
mu <- mean(train_edx$rating)
```
Fit the model
```{r b_u}
fit_user_ave <- 
  train_edx %>% 
  group_by(userId) %>% 
  summarize(b_u = mean(rating - mu))
```
Predict the rarings
```{r user effect predicted ratings}
predicted_ratings <- 
  test_edx %>% 
  left_join(fit_user_ave, by='userId') %>% 
  mutate(predicted=mu+b_u) %>%
  pull(predicted)
```
The estimates........ 
```{r plot b_u and predicted, echo=FALSE}
# plot the user spesific effect - these estimates very substantially
# figure 8 # 
user_b_u <- 
  fit_user_ave %>%
  ggplot(aes(b_u))+
  geom_histogram(bins=30, color="black")+
  geom_vline(aes(xintercept=mu),color="red", linetype="dashed", size=0.5)+
  ggtitle("")+
  labs(x="b_u", y="number of users")

# plot the user predicred rating
# figure 9 # 
user_predicted_ratings <-
  test_edx %>% 
  left_join(fit_user_ave, by='userId') %>% 
  mutate(predicted=mu+b_u)%>% 
  group_by(userId) %>% 
  summarise(predicted=mean(predicted)) %>% 
  ggplot(aes(predicted))+
  geom_histogram(bins=30, color="black")+
  geom_vline(aes(xintercept=mu),color="red", linetype="dashed", size=0.5)+
  ggtitle("Rating score dist. by number of users")+ 
  labs(x="Predicted Rating score", y="number of users")

# display 2 plots together
grid.arrange(user_b_u,user_predicted_ratings, ncol=2)
```

#### model results
```{r model results user effect}
# model RMSE
model_1_rmse <- RMSE(true_ratings=test_edx$rating,
                     predicted_ratings=predicted_ratings)
# model MSE
model_1_mse <- MSE(test_edx$rating,predicted_ratings)

#add the results to the table 
model_1_results <- tibble(method = "User Effect",MSE=model_1_mse, RMSE = model_1_rmse)
model_1_results 
```
we obtain RMSE = 0.9791, only 8% improvement from the naive model. 

```{r plot the user mse, echo=FALSE}
# figure 9 #
test_edx %>% 
  left_join(fit_user_ave, by='userId') %>% 
  select(userId,rating,b_u, title) %>% 
  mutate(predicted=b_u+mu,
         se=((rating-predicted)^2)) %>%
  group_by(userId) %>% 
  summarise(mse=mean(se)) %>% 
  ggplot(aes(mse))+
  geom_histogram(bins=30, color="black")+
  geom_vline(aes(xintercept=mean(mse)),color="red", linetype="dashed", size=0.5)+
  ggtitle("User Effect model squared errors")+ 
  labs(x="Mean squared errors", y="number of users")
```
```{r se user, echo=FALSE}
test_edx %>% 
  left_join(fit_user_ave, by='userId') %>% 
  select(userId,rating,b_u) %>% 
  mutate(predicted=b_u+mu,
         squared_errors=(rating-predicted)^2) %>% 
  select(squared_errors) %>% 
  summary()
``` 


#### Regularization #
lambda is a tuning parameter. we will use cross-validation to choose it. 
we'll create additional partition of the training for cross validation, pick the lambda and evaluate the performance on the previos train+test. 

```{r cv partition}
set.seed(2020, sample.kind="Rounding") 
# if using R 3.5 or earlier, use `set.seed(2020)`

# randomly splitting train set into 90% training set and 10% testing set 
test_index_cv <- 
  createDataPartition(y = train_edx$rating, 
                      times = 1, p = 0.1, list = FALSE)

train_edx_cv <- train_edx %>% slice(-test_index_cv)
temp <- train_edx %>% slice(test_index_cv)

# making sure that the test set includes users and movies that appear in the training set.

test_edx_cv <- 
  temp %>% 
  semi_join(train_edx_cv, by = "movieId") %>%
  semi_join(train_edx_cv, by = "userId")

removed <- anti_join(temp, test_edx_cv)
train_edx_cv <- rbind(train_edx_cv, removed)
rm(temp, removed)
```

choosing penalty term (lambda) for user effect
```{r lambda for user effect}
equation_mu <- mean(train_edx_cv$rating)

equation_sum_u <- 
  train_edx_cv %>%
  group_by(userId) %>%
  summarize(n_i=n(), 
            s=sum(rating-equation_mu))

lambdas <- seq(0,7,0.05)

user_rmses <- 
  sapply(lambdas,function(lambda){
    reg_predicted_ratings <- 
      test_edx_cv %>%
      left_join(equation_sum_u, by="userId") %>%
      mutate(reg_b_u=(s/(n_i+lambda)),
             predicted=(equation_mu+reg_b_u)) %>%
      pull(predicted)
    
    return(RMSE(true_ratings=test_edx_cv$rating,
                predicted_ratings=reg_predicted_ratings))
  })

qplot(lambdas,user_rmses)
```

```{r user effect panelty term}
penalty_term <- lambdas[which.min(user_rmses)]
penalty_lambda_rmse <- c(penalty_term,user_rmses[lambda=penalty_term])
penalty_lambda_rmse
```

apply lambda on edx train and test set
```{r fir reg user effect}
fit_reg_user_ave <- 
  train_edx %>% 
  group_by(userId) %>% 
  summarize(n_i=n(), 
            reg_b_u=(sum(rating - mu)/(n_i+penalty_term)))
```
panelized prediction
```{r reg predicted rating user}
reg_predicted_ratings <- 
  test_edx %>% 
  left_join(fit_reg_user_ave, by='userId') %>%
  mutate(predicted=mu+reg_b_u) %>%
  pull(predicted)
```
panelized model results 
```{r reg user effect results}
model_1_1_rmse <- RMSE(true_ratings=test_edx$rating,
                       predicted_ratings=reg_predicted_ratings)
model_1_1_mse <- MSE(test_edx$rating,reg_predicted_ratings)

#add the results to the table 
model_1_1_results <- tibble(method = "Reg. User Effect",
                            MSE=model_1_1_mse, RMSE = model_1_1_rmse)
model_1_1_results
```

```{r reg se user}
test_edx %>% 
  left_join(fit_reg_user_ave, by='userId') %>% 
  select(userId,rating,reg_b_u) %>% 
  mutate(predicted=reg_b_u+mu,
         reg_squared_errors=(rating-predicted)^2) %>% 
  select(reg_squared_errors) %>% 
  summary()
```
we obtain RMSE= 0.9785479, the panelized estimates does not provide much improvement to the RMSE. 

moving forward by testing the movie specific effect on the predicrion.

### 9. movieId

#### Movie Rating
```{r movie summarize, echo=FALSE}
train_edx %>% 
  group_by(movieId) %>%
  summarize(count=n()) %>% 
  summarize(mean=round(mean(count)), 
            median=median(count), 
            mode=Mode(count,na.rm=FALSE), 
            min=min(count), max=max(count)) %>%
  knitr::kable()
```
In average, each one of the 10.6k different movies get rated 674 times.

the movies most frequently gets only 1 ratings, but there are exeptional like "Pulp Fiction" that got rated 3734% (!!!) more than average with 25169 users ratings.

the distribution is positively skewed, like the user activity dist as the mean is larger than the mode and median.
```{r number of rating dist vs movie, echo=FALSE}
# figure 10 # 
# graph number of rating dist. by number of movies 
movie_hist <- 
  train_edx %>% 
  group_by(movieId) %>%
  summarize(count=n()) %>%
  ggplot(aes(count)) +
  geom_histogram(bins = 30, color = "gray20")+ 
  geom_vline(aes(xintercept=median(count),color="median"), 
                 linetype="dashed", size=0.5)+
  geom_vline(aes(xintercept=Mode(count, na.rm = FALSE),color="Mode"),
                 linetype="dashed", size=0.5)+
  geom_vline(aes(xintercept=mean(count),color="mean"), 
                 linetype="dashed", size=0.5)+
  scale_color_manual(name = "Statistics", 
                     values = c(median = "skyblue1", mean = "pink1",Mode="blue"))+
  scale_x_log10()+
  ggtitle("movieId Distribution")+ 
  labs(x="Number Of Ratings Count", y="Number of Movies") 

#graph number of ratings per movie, see extreme observation
# figure 11 # 
rate_p_m<- 
  train_edx %>% 
  group_by(title) %>%
  summarize(count=n()) %>%
  ggplot(aes(title,count)) +
  geom_point(alpha=0.1)+
  geom_hline(aes(yintercept=mean(count)),color="pink1", 
                 linetype="dashed", size=0.5)+
  geom_hline(aes(yintercept=Mode(count, na.rm = FALSE)),
                 color="blue", linetype="dashed", size=0.5)+
  geom_hline(aes(yintercept=median(count)),color="skyblue1", 
                 linetype="dashed", size=0.5)+
  ggtitle("Total Number Of Ratings Per Movie")+ 
  labs(x="10,677 Unique Movies", y="Total Ratings Per Movie") + 
  theme(axis.text.x=element_blank(), axis.ticks.x=element_blank())

# plot 2 graphs - place multiple grobs on a page
grid.arrange(rate_p_m, movie_hist, ncol=2)
```

```{r movie rating dist quantiles, include=FALSE}
train_edx %>% 
  group_by(movieId) %>% 
  summarise(rating_score=mean(rating)) %>% summary(rating_score)
```
Some movies are just generally rated higher than others. 

50% of the ratints are between 2.8 to 3.6 stars. very few gets prefect 5 srars
Respectively very few got the shady 1 star. 
```{r movie rating dist, echo=FALSE}
# figure 12 # 
train_edx %>% 
  group_by(movieId) %>% 
  summarise(rating_score=mean(rating)) %>% 
  ggplot(aes(rating_score))+
  geom_histogram(bins=30, color="black")+
  geom_vline(aes(xintercept=mu),color="red", linetype="dashed", size=0.5)+
  ggtitle("Rating score dist. by number of movies")+ 
  labs(x="Rating score", y="number of movies")
```

####  c. second model - modeling movie effect



```{r fit movie ave}
fit_movie_ave <- 
  train_edx %>% 
  group_by(movieId) %>% 
  summarize(b_i = mean(rating - mu))
```
how much our prediction improves once using y=mu+bi
```{r movie predicted ratings}
predicted_ratings <- 
  test_edx %>% 
  left_join(fit_movie_ave, by='movieId') %>%
  mutate(predicted = mu + b_i) %>% 
  pull(predicted)
```
The estimates........ 
```{r plot b_i and predicted, echo=FALSE}
# plot the movie spesific effect - these estimates very substantially
# figure 13 # 
movie_b_i <-
  fit_movie_ave %>%
  ggplot(aes(b_i))+
  geom_histogram(bins=30, color="black")+
  geom_vline(aes(xintercept=mu),color="red", linetype="dashed", size=0.5)+
  ggtitle("")+
  labs(x="b_i", y="number of movies")

# plot the movie predicted rating
# figure 14 # 
movie_predicted_ratings <-
  test_edx %>% 
  left_join(fit_movie_ave, by='movieId') %>% 
  mutate(predicted=mu+b_i)%>% 
  group_by(movieId) %>% 
  summarise(predicted=mean(predicted)) %>% 
  ggplot(aes(predicted))+
  geom_histogram(bins=30, color="black")+
  geom_vline(aes(xintercept=mu),color="red", linetype="dashed", size=0.5)+
  ggtitle("Rating score dist. by number of movies")+ 
  labs(x="predicted Rating score", y="number of movies")

# plot 2 graphs together
grid.arrange(movie_b_i ,movie_predicted_ratings, ncol=2)
```
### model results
```{r movie effect model results}
# model RMSE
model_2_rmse <- RMSE(true_ratings=test_edx$rating,
                     predicted_ratings=predicted_ratings)
# model MSE
model_2_mse <- MSE(test_edx$rating,predicted_ratings)

#add the results to the table 
model_2_results <- tibble(method = "Movie Effect",
                          MSE=model_2_mse, RMSE = model_2_rmse)
model_2_results
```
We obtain RMSE=0.9439868, improvement of 11% from the naice mosel RMSE

```{r plot movie mse, echo=FALSE}
# figure 15 #
test_edx %>% 
  left_join(fit_movie_ave, by='movieId') %>% 
  select(movieId,rating,b_i, title) %>% 
  mutate(predicted=b_i+mu,
         se=((rating-predicted)^2)) %>%
  group_by(movieId) %>% 
  summarise(mse=mean(se)) %>% 
  ggplot(aes(mse))+
  geom_histogram(bins=30, color="black")+
  geom_vline(aes(xintercept=mean(mse)),color="red", linetype="dashed", size=0.5)+
  ggtitle("User Effect model squared errors")+ 
  labs(x="Mean squared errors", y="number of movies")
```

```{r se movie summary}
test_edx %>% 
  left_join(fit_movie_ave, by='movieId') %>% 
  select(movieId,rating,b_i) %>% 
  mutate(predicted=b_i+mu,
         squared_errors=(rating-predicted)^2) %>% 
  select(squared_errors) %>% 
  summary()
```
The squared errors distribution is large, which indicate low accuracy. The mse distribution tail quite shorter than the User effect model, but can be improved by penalize the outliers. 

#### Regularization #
choosing penalty term (lambda) for movie effect

```{r lambda for movie effect, echo=TRUE}
equation_mu <- mean(train_edx_cv$rating)

equation_sum_m <- 
  train_edx_cv %>%
  group_by(movieId) %>%
  summarize(n_i=n(), 
            s=sum(rating-equation_mu))

lambdas <- seq(0,6,0.05)

movie_rmses <- 
  sapply(lambdas,function(lambda){
    reg_predicted_ratings <- 
      test_edx_cv %>%
      left_join(equation_sum_m, by="movieId") %>%
      mutate(reg_b_i=(s/(n_i+lambda)),
             predicted=(equation_mu+reg_b_i)) %>%
      pull(predicted)
    return(RMSE(true_ratings=test_edx_cv$rating,
                predicted_ratings=reg_predicted_ratings))
  })

qplot(lambdas,movie_rmses)
```

```{r movie effect panelty term}
penalty_term <- lambdas[which.min(movie_rmses)]
penalty_lambda_rmse <- c(penalty_term,movie_rmses[lambda=penalty_term])
penalty_lambda_rmse
```

Apply lambda on edx train and test set
```{r fit reg movie ave}
fit_reg_movie_ave <- 
  train_edx %>% 
  group_by(movieId) %>% 
  summarize(n_i=n(), 
            reg_b_i=(sum(rating - mu)/(n_i+penalty_term)))
```
Penalized prediction
```{r reg predicted movie ratings}
reg_predicted_ratings <- 
  test_edx %>% 
  left_join(fit_reg_movie_ave, by='movieId') %>%
  mutate(predicted=mu+reg_b_i) %>%
  pull(predicted)
```
Penalize model results
```{r reg movie model result}
model_2_1_rmse <- RMSE(true_ratings=test_edx$rating,
                       predicted_ratings=reg_predicted_ratings)

model_2_1_mse <- MSE(test_edx$rating,reg_predicted_ratings)

#add the results to the table 
model_2_1_results <- tibble(method = "Reg. Movie Effect",
                            MSE=model_2_1_mse, RMSE = model_2_1_rmse)
model_2_1_results
```
The penalized model obtain RMSE= 0.9439218. there is no improvement with the penalty term. 
```{r se movie}
test_edx %>% 
  left_join(fit_reg_movie_ave, by='movieId') %>% 
  select(movieId,rating,reg_b_i) %>% 
  mutate(predicted=reg_b_i+mu,
         reg_squared_errors=(rating-predicted)^2) %>% 
  select(reg_squared_errors) %>% 
  summary()
```

to see how the estimates shrink, plot the regularized estimates vs least squre estimates 
```{r estimated plot}
# figure 16 #
data_frame(original = fit_movie_ave$b_i, 
           regularlized = fit_reg_movie_ave$reg_b_i, 
           n = fit_reg_movie_ave$n_i) %>%
  ggplot(aes(original, regularlized, size=sqrt(n))) + 
  geom_point(shape=1, alpha=0.5) 
```
The size of the circle represent the size of n_i (count of ratings). 

When n_i is small, the values are shrinking more toward zero. 

### 10. movieId + userId
####  D. third model - modeling movie + user effect



Fit the model
```{r fit movie user ave}
fit_user_movie_ave <- 
  train_edx %>% 
  left_join(fit_movie_ave, by='movieId') %>%
  group_by(userId) %>%
  summarize(b_ui = mean(rating - mu - b_i))
```

how much our prediction improves once using y=mu+bi+b_ui
```{r movie user predicted ratings}
predicted_ratings <- 
  test_edx %>% 
  left_join(fit_movie_ave, by='movieId') %>%
  left_join(fit_user_movie_ave, by='userId') %>%
  mutate(predicted = mu+b_i+b_ui) %>%
  pull(predicted)
```
#### model results
```{r model 3 results}
# model RMSE
model_3_rmse <- RMSE(true_ratings=test_edx$rating,
                     predicted_ratings=predicted_ratings)
# model MSE
model_3_mse <- MSE(test_edx$rating,predicted_ratings)

#add the results to the table 
model_3_results <- tibble(method = "Movie + User Effect",
                          MSE=model_3_mse, RMSE = model_3_rmse)
model_3_results
```
The model RMSE= 0.8666408, 18.2% improvement from the naive model. 

The model squared errors 
```{r plot movie and user mse, echo=FALSE}
# figure 17 #
test_edx %>% 
  left_join(fit_movie_ave, by='movieId') %>%
  left_join(fit_user_movie_ave, by="userId") %>%
  select(movieId,userId,rating,b_i,b_ui,title) %>% 
  mutate(predicted=mu+b_i+b_ui,
         se=((rating-predicted)^2)) %>%
  group_by(movieId) %>% 
  summarise(mse=mean(se)) %>% 
  ggplot(aes(mse))+
  geom_histogram(bins=30, color="black")+
  geom_vline(aes(xintercept=mean(mse)),color="red", linetype="dashed", size=0.5)+
  ggtitle("Movie + User Effect model squared errors")+ 
  labs(x="Mean squared errors", y="number of movies")
```

```{r se movie+user, echo=FALSE}
test_edx %>% 
  left_join(fit_movie_ave, by='movieId') %>%
  left_join(fit_user_movie_ave, by="userId") %>%
  select(movieId,userId,rating,b_i,b_ui) %>% 
  mutate(predicted=mu+b_i+b_ui,
         squared_errors=(rating-predicted)^2) %>% 
   select(squared_errors) %>%
  summary()
```
Althogh we saw RMSE improvement, the squared error shows large distribution. 
we will try to "fix" it by the penalizing and reduse very large absulute values of b_i and b_u_i

#### Regularization #
choosing penalty terms 
```{r model 3.1 penalty term}
lambdas <- seq(0,10,0.25)

equation_mu <- mean(train_edx_cv$rating)

movie_user_rmses <- 
  sapply(lambdas,function(lambda){
    fit_reg_movie_ave <- 
      train_edx_cv %>% 
      group_by(movieId) %>%
      summarize(n_i=n(),
                s= sum(rating - equation_mu),
                reg_b_i=(s/(n_i+lambda)))
    
    fit_reg_user_movie_ave <- 
      train_edx_cv %>%
      left_join(fit_reg_movie_ave, by='movieId') %>%
      group_by(userId) %>%
      summarize(n_i=n(), 
                s= sum(rating -reg_b_i -equation_mu), 
                reg_b_ui=(s/(n_i+lambda)))
    
    reg_predicted_ratings <- 
      test_edx_cv %>% 
      left_join(fit_reg_movie_ave, by='movieId') %>%   
      left_join(fit_reg_user_movie_ave, by='userId') %>%
      mutate(predicted = equation_mu+reg_b_i+reg_b_ui) %>%
      pull(predicted)
    
    return(RMSE(true_ratings=test_edx_cv$rating,
                predicted_ratings=reg_predicted_ratings))
    
  })

qplot(lambdas,movie_user_rmses)
```

```{r model 3 lambda}
penalty_term <- lambdas[which.min(movie_user_rmses)]
penalty_lambda_rmse <- c(penalty_term,movie_user_rmses[lambda=penalty_term])
penalty_lambda_rmse
```
apply lambda on edx train and test set
```{r fet reg movie user ave}
fit_reg_movie_ave <- 
  train_edx %>%
  group_by(movieId) %>%
  summarize(n_i=n(), 
            s= sum(rating - mu),
            reg_b_i=(s/(n_i+penalty_term)))

fit_reg_user_movie_ave <- 
  train_edx %>%
  left_join(fit_reg_movie_ave, by='movieId') %>%
  group_by(userId) %>% 
  summarize(n_i=n(),
            s= sum(rating -reg_b_i -mu), 
            reg_b_ui=(s/(n_i+penalty_term)))
```
Penalized prediction
```{r movie+user efect predicted ratings}
predicted_ratings <- 
  test_edx %>%
  left_join(fit_reg_movie_ave, by='movieId') %>%
  left_join(fit_reg_user_movie_ave, by='userId') %>%
  mutate(predicted = mu+reg_b_i+reg_b_ui) %>%
  pull(predicted)
```
Penalized model results
```{r model 3.1 results}
model_3_1_rmse <- RMSE(true_ratings=test_edx$rating,
                       predicted_ratings=predicted_ratings)

model_3_1_mse <- MSE(test_edx$rating,reg_predicted_ratings)

#add the results to the table 
model_3_1_results <- tibble(method = "Reg. Movie + User Effect",
                            MSE=model_3_1_mse, RMSE = model_3_1_rmse)
model_3_1_results
```
The penalized model obtain RMSE = 0.8659649
```{r reg movie user squared errors summary, echo=FALSE}
test_edx %>%
  left_join(fit_reg_movie_ave, by='movieId') %>%
  left_join(fit_reg_user_movie_ave, by='userId') %>%
  mutate(predicted = mu+reg_b_i+reg_b_ui,
         reg_squared_errors=(rating-predicted)^2) %>% 
  select(reg_squared_errors) %>% 
  summary()
```
to see how the estimates shrink, plot the regularized estimates vs least squre estimates 
```{r plot estimate}
# figure 18 #
data_frame(original = fit_user_movie_ave$b_ui, 
           regularlized = fit_reg_user_movie_ave$reg_b_ui,
           n=fit_reg_user_movie_ave$n_i) %>%
  ggplot(aes(original, regularlized, size=sqrt(n))) + 
  geom_point(shape=1, alpha=0.5) 
```
 
### 11. Age of the movie at rating
#### how old was the movie during rating
Having the joint effect of movie and user is not enough since The users ratings are affected by other factors. 

One factor for exampe, is the age of the movie at rating. There are users that likes the quality of "old times" movies and favors aged movies, regardless of the specific movie. It can be considered as "Old Movies Gener".

we will model the effect of the age of the movie on the user.

We also need to rememmber that a movie can be rated multiple times by different users at different years. 

Age of a movie at tating summary; 
```{r age summarize, echo=FALSE}
train_edx %>% 
  mutate(age_at_rating= abs(rate_year-release_year)) %>%
  filter(age_at_rating>=0)%>%
  summarize(mean=mean(age_at_rating), 
            median=median(age_at_rating), 
            mode=Mode(age_at_rating,na.rm=FALSE), 
            min=min(age_at_rating), max=max(age_at_rating)) %>% 
  knitr::kable() 
```
The average age of the movies is 12 years. 

The yungest movies being rated were the ones thet rated the same year of release. the oldest is 93 years old. 

most frequently rated are movies one year after they released. 

The next tile plot shows the average score of the movies at rating vs. their release year. 
The tiled colors represent the rate score; darker tile indicate higher score.

we can see that older movies score higher in average, but the effect is not significant.  

```{r rate year vs release year, echo=FALSE}
# figure 19 # 
scoring_by_age <- 
  train_edx %>% 
  group_by(title,rate_year) %>% 
  summarize(count=n(), 
            Ave_rating_score=mean(rating),
            rate_year=rate_year[1], 
            release_year=release_year[1]) %>%
  ggplot(aes(x=release_year,y=rate_year,fill=Ave_rating_score)) + 
  geom_tile() + 
  coord_fixed(expand = FALSE)+
  scale_fill_continuous_sequential(palette = "Blues")+
  ggtitle(" Movie Rating score - Release Year Vs. Rate Year")+ 
  labs(x="Movie Release Year", y="Movie Rate Year") 

# figure 20#
# graph - average scoring by age
ave_scoring_by_age <- 
  train_edx %>% 
  group_by(title,rate_year) %>% 
  summarize(count=n(), 
            Ave_rating_score=mean(rating),
            rate_year=rate_year[1], 
            release_year=release_year[1]) %>% 
  group_by(release_year) %>% #mutate(ave=mean(Ave_rating_score)) %>%
  ggplot(aes(x=release_year,y=as.character('mean'),fill=Ave_rating_score)) + 
  geom_tile() + 
  coord_fixed(expand = FALSE)+
  scale_fill_continuous_sequential(palette = "Blues")+
  ggtitle("mean Movie Rating score")+ 
  labs(x="Movie Release Year", y="mean") 

# plot 2 graphs - place multiple grobs on a page
plot_grid(ave_scoring_by_age, scoring_by_age, ncol=1, align="v") # TO DO- share legends 
```
The next table show example of movies with more than total of 1000 ratings, that released in 1984. 

The rate years are 1999-2000, means the age of the movies at rating is around 3 to 4 years. 

in this random example we can see the change of the average rating csore for each movie by its age, and the average rate score of the entire rate year.  

1984 release year example (filter movies with less than 1000 ratings)
```{r 1984 release year example, echo=FALSE}
age_ex._1984 <- 
  train_edx %>% 
  group_by(title, rate_year) %>%
  summarize(count=n(),Ave_rating_score = round(mean(rating),3),
            rate_year=rate_year[1],
            release_year=release_year[1]) %>% 
  filter(release_year=="1984" & count>1000) %>% 
  group_by(rate_year) %>%
  mutate(ave = round(mean(Ave_rating_score),3)) %>% arrange(rate_year)
# display first 10 in a table
age_ex._1984[1:10,] %>% 
  knitr::kable() 
``` 

The next plot represent the averge rate score of the age at rating (for movies with 5k total ratings and up). 

Old movies score higher, but they also rated less times, which need to take into panelize considaration.  
```{r age ave rating, echo=FALSE}
# figure 21 #
train_edx %>% 
  mutate(age_at_rating= abs(rate_year-release_year)) %>%
  filter(age_at_rating>=0)%>%
  group_by(age_at_rating) %>%
  summarize(k_count=n()/1000, ave=mean(rating)) %>% filter(k_count>5) %>%
  ggplot(aes(age_at_rating,ave)) +
  geom_line(aes(color = k_count))+
  scale_color_gradient2(low = 'white', mid ='blue' , high = 'red')+
  geom_hline(aes(yintercept=mean(train_edx$rating)),color="blue", linetype="dashed", size=0.5)+
  ggtitle("average Ratings distribution by the age of the movie")+ 
  labs(x="Age of a movie at rating", y="Average rating score")
```
The points at the plot represent different movies. 
There are much more newer movies than older, However there is some avidence for age effect 
```{r avidence for age effect, echo=FALSE}
# figure 22 # 
train_edx %>% 
  mutate(age_at_rating= abs(rate_year-release_year)) %>%
  filter(age_at_rating>=0)%>%
  group_by(title) %>%
  summarize(count = n(), 
            ave_age_at_rating=mean(age_at_rating),
            ave_rating = mean(rating)) %>%
  ggplot(aes(ave_age_at_rating, ave_rating)) +
  geom_point() + 
  geom_smooth()+
  ggtitle("")+ 
  labs(x="ave age at rating", y="Average Rating Score") 
```

#### Classical Hollywood cinema

Classical Hollywood cinema, a gener of age, is a term used in film criticism to describe both a narrative and visual style of filmmaking which became characteristic of American cinema between the 1910s (rapidly after World War I) and the 1960s.

(https://en.wikipedia.org/wiki/Classical_Hollywood_cinema) # TO DO - HYPERLINK

There are 1.3k Classical Hollywood cinema movies in our data with average age of 54 years old and average rating of 3.9 stars, 0.4 stara more than the general averge.   
```{r classical summarize, echo=FALSE}
train_edx %>% 
  mutate(age_at_rating= abs(rate_year-release_year)) %>%
  filter(age_at_rating>=0 & release_year %in% "1915":"1960") %>%
  summarize(n_movies=n_distinct(movieId),
            ave_rating=mean(rating),
            ave_age=mean(age_at_rating),
            min_age=min(age_at_rating), 
            max_age=max(age_at_rating)) %>%
  knitr::kable()
```

Classical Hollywood cinema 36-93 years old movies and their average score as shown;
```{r graph old movies, echo=FALSE}
# figure 23 #
train_edx %>% 
  mutate(age_at_rating= abs(rate_year-release_year)) %>%
  filter(age_at_rating>=0 & release_year %in% "1915":"1960") %>%
  group_by(age_at_rating) %>%
  summarize(count=n(), 
            ave=mean(rating), 
            rating=rating[1]) %>% 
  ggplot(aes(age_at_rating,ave)) +
  geom_point(aes(color = count))+
  geom_hline(aes(yintercept=3.899027),color="blue", linetype="dashed", size=0.5)+
  scale_color_gradient2(low = 'white', mid ='blue' , high = 'red')+
  ggtitle("Classical Hollywood cinema movies 1915-1960")+ 
  labs(x="Age of a movie at rating", y="average rating score") 
```

#### E. forth model Reg. User + Age of the movie at rating Effect

The model will group the age of the movie at rating regardles it title since
each movie rated several times over the years. 

Previous analysis on the user effect taught us that the model shuold be penalized, also, the analysis on the age at rating indicate of large variation between the rating counts and the rating scores.

The model <TODO> WRITE THE MODEL FORM

b_a- <TODO>

We'll choose penalize model in advance; 

Choosing penalty term
```{r model 4 penalty term} 
lambdas <- seq(0,10,0.25)

equation_mu <- mean(train_edx_cv$rating)

user_age_rmses <- 
  sapply(lambdas,function(lambda){
    fit_reg_user_ave <- 
      train_edx_cv %>% 
      mutate(age_at_rating= abs(rate_year-release_year)) %>%
      filter(age_at_rating>=0)%>%
      group_by(userId) %>%
      summarize(n_i=n(),
                s= sum(rating - equation_mu),
                reg_b_u=(s/(n_i+lambda)))
    
    fit_reg_user_age_ave <- 
      train_edx_cv %>%
      mutate(age_at_rating= abs(rate_year-release_year)) %>%
      filter(age_at_rating>=0)%>%
      left_join(fit_reg_user_ave, by='userId') %>%
      group_by(age_at_rating) %>%
      summarize(n_i=n(), 
                s= sum(rating -reg_b_u -equation_mu), 
                reg_b_ua=(s/(n_i+lambda)))
    
    reg_predicted_ratings <- 
      test_edx_cv %>% 
      mutate(age_at_rating= abs(rate_year-release_year)) %>%
      filter(age_at_rating>=0)%>%
      left_join(fit_reg_user_ave, by='userId') %>%   
      left_join(fit_reg_user_age_ave, by='age_at_rating') %>%
      mutate(predicted = equation_mu+reg_b_u+reg_b_ua) %>%
      pull(predicted)
    
    return(RMSE(true_ratings=test_edx_cv$rating,
                predicted_ratings=reg_predicted_ratings))
  })

qplot(lambdas,movie_user_rmses)
```

```{r model 4 lambda}
penalty_term <- lambdas[which.min(user_age_rmses)]
penalty_lambda_rmse <- c(penalty_term,user_age_rmses[lambda=penalty_term])
penalty_lambda_rmse
```
Apply lambda on edx train and test set
```{r fit age ave}
fit_reg_user_ave <- 
  train_edx %>%
  mutate(age_at_rating= abs(rate_year-release_year)) %>%
  filter(age_at_rating>=0)%>%
  group_by(userId) %>%
  summarize(n_i=n(), 
            s= sum(rating - mu),
            reg_b_u=(s/(n_i+penalty_term)))

fit_reg_user_age_ave <- 
  train_edx %>%
  mutate(age_at_rating= abs(rate_year-release_year)) %>%
  filter(age_at_rating>=0)%>%
  left_join(fit_reg_user_ave, by='userId') %>%
  group_by(age_at_rating) %>% 
  summarize(n_i=n(),
            s= sum(rating -reg_b_u -mu), 
            reg_b_ua=(s/(n_i+penalty_term)))
```
Penalized predicted ratings
```{r age predicted rating}
predicted_ratings <- 
  test_edx %>%
  mutate(age_at_rating= abs(rate_year-release_year)) %>%
  filter(age_at_rating>=0)%>%
  left_join(fit_reg_user_ave, by='userId') %>%
  left_join(fit_reg_user_age_ave, by='age_at_rating') %>%
  mutate(predicted = mu+reg_b_u+reg_b_ua) %>%
  pull(predicted)
```
# Penalized model results
```{r model 4 results}
model_4_rmse <- RMSE(true_ratings=test_edx$rating,
                     predicted_ratings=predicted_ratings)

model_4_mse <- MSE(test_edx$rating,reg_predicted_ratings)

#add the results to the table 
model_4_results <- 
  tibble(method = "Reg. User + Age of the movie at rating Effect",
          MSE=model_4_mse, RMSE = model_4_rmse)
model_4_results
```
The penalized model obtain RMSE 0.9712367, improvement of only 8.3 than the naive model and only 1% better than the user effect model. 

The residual summary as shown; 
```{r reg user age squared errors summary, echo=FALSE}
test_edx %>%
  mutate(age_at_rating= abs(rate_year-release_year)) %>%
  filter(age_at_rating>=0)%>%
  left_join(fit_reg_user_ave, by='userId') %>%
  left_join(fit_reg_user_age_ave, by='age_at_rating') %>%
  mutate(predicted = mu+reg_b_u+reg_b_ua,
         reg_squared_errors=(rating-predicted)^2) %>% 
  select(reg_squared_errors) %>% 
  summary()
```

```{r user age mse plot, echo=FALSE}
test_edx %>%
  mutate(age_at_rating= abs(rate_year-release_year)) %>%
  filter(age_at_rating>=0)%>%
  left_join(fit_reg_user_ave, by='userId') %>%
  left_join(fit_reg_user_age_ave, by='age_at_rating') %>%
  mutate(predicted = mu+reg_b_u+reg_b_ua,
         se=((rating-predicted)^2)) %>%
  group_by(userId) %>% 
  summarise(mse=mean(se)) %>% 
  ggplot(aes(mse))+
  geom_histogram(bins=30, color="black")+
  geom_vline(aes(xintercept=mean(mse)),color="red", linetype="dashed", size=0.5)+
  ggtitle("")+ 
  labs(x="Mean squared errors", y="number of users")
```
The model MSE distribution show long right tail that indicate low accuracy. 

We'll move forward and look for more influencing factors. 

### 12. Time Frame Ranges

Movie release streched over 93 years, while they first started to be rated after 80 years 
```{r time frame ranges, echo=FALSE}
tibble(Year = c("Release", "rate"),
       First = c(min(train_edx$release_year),min(train_edx$rate_year)), 
       Last = c(max(train_edx$release_year),max(train_edx$rate_year)),
       "Range in years" = Last-First) %>% 
  knitr::kable()
```

#### Release year

The number of ratings for each movie against the year the movie came out
(Each point represent different movie); 
```{r number of rating per movie over time, echo=FALSE, out.width = '100%'}
# figure 24 #
train_edx %>% 
  group_by(movieId) %>% 
  summarize(count = n(), 
            year = as.character(first(release_year))) %>% 
  ggplot(aes(year, count))+
  geom_boxplot(aes(group = cut_width(year, 0.2)), outlier.alpha = 0.1)+
  geom_hline(aes(yintercept=mean(count)),color="red", 
                 linetype="dashed", size=0.5)+ 
  coord_trans(y = "sqrt") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size = rel(0.7)))+
  ggtitle("number of rating for each movie per release year")+ 
  labs(x="Movie Release Year", y="number of ratings per movie") 
```
362 movies that releasd in 1995 got the higest ratings count.

Movies that released between the years 1992-1999 shows above average ratings count while starting in 1993 the number of the movies being rated decreases with year. 

The more recent movie is, the less time users have had to rate it. 

In addition, as the total rating count increases, the total rating score decreases. 

Newer released movies gets more rated, but the amount of the ratings affects the average score and lower it. 
```{r average rating score for each release year, echo=FALSE}
# figure 25 # 
train_edx %>% 
  group_by(release_year) %>%
  summarize(k_count=n()/1000,      # count in thousands
            rating_score = mean(rating)) %>%
  ggplot(aes(release_year, rating_score)) +
  geom_point(aes(color=k_count)) + 
  scale_color_gradient2(high = 'black', mid ='gray' ,low = 'white' )+
  geom_smooth()+
  geom_hline(aes(yintercept=mean(edx_year_sanitized$rating)),
             color="red", linetype="dashed", size=0.5)+
  ggtitle("Average Rating Per year")+ 
  labs(x="Release Year", y="Average Rating Score") 
```
The next plot shows post-1993 movies - ratings per year and their average ratings. Each point represent unique movie. 

As the rating per year increases, the average rate score increases, in other words; The more often a movie is rated, the higher its average rating.  
```{r post-1993 movies, echo=FALSE}
# figure 26 # 
train_edx %>% 
  filter(release_year >= 1993) %>%
  group_by(movieId) %>%
  summarize(count = n(), 
            years = 2018 - first(release_year),
            title = title[1],
            ave_rating = mean(rating)) %>%
  mutate(rating_per_year = count/years) %>%
  ggplot(aes(rating_per_year, ave_rating)) +
  geom_point() +
  geom_smooth()+
  ggtitle("post-1993 movies ratings per year and their average ratings")+ 
  labs(x="Rating Per Year", y="Average Rating Score") 
```
Here are the top 10 movies with the most ratings per year, along with their average ratings (represent the upper right part of the previous plot)
```{r top 10 movies,echo=FALSE}
train_edx %>% 
  filter(release_year >= 1993) %>%
  group_by(movieId) %>%
  summarize(title = title[1], 
            Total_ratings_count = n(), 
            years = 2018 - first(release_year),
            ave_rating = round(mean(rating),2)) %>%
  mutate(rating_per_year =round( Total_ratings_count/years,2)) %>%
  top_n(10, rating_per_year) %>% select(-movieId) %>%
  arrange(desc(rating_per_year, years)) %>%
  knitr::kable()
```

### Rate year
The numbers of the movies being rated generaly decreases every year. 

The trend of the average rating score is not distinct, but both plot indicate that there is some evidence of a time effect on average rating.
```{r time effect evidance, echo=FALSE, out.width = '80%'}
# graph Number of movies per each rate year
# figure 27 # 
rating_count_per_rate_year <- 
  train_edx %>% 
  group_by(movieId) %>%
  summarize(count = n(), 
            rate_year = as.character(first(rate_year))) %>%
  qplot(rate_year, count, data = ., geom = "boxplot") +
  coord_trans(y = "sqrt") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))+
  geom_hline(aes(yintercept=mean(count)),color="red", linetype="dashed", size=0.5)+
  ggtitle("number of movies Per rate year")+ 
  labs(x="Rate Year", y="Movies count") 

# graph average rating for each week 
# figure 28 #
score_by_week <- 
  train_edx %>% 
  mutate(week_of_rate = round_date(rate_date, unit = "week")) %>%
  group_by(week_of_rate) %>%
  summarize(rating_score = mean(rating)) %>%
  ggplot(aes(week_of_rate, rating_score)) +
  geom_point() +
  geom_smooth()+
  geom_hline(aes(yintercept=mean(rating_score)),color="red", linetype="dashed", size=0.5)+
  ggtitle("Average Rating Per Week")+ 
  labs(x="Week of rate", y="Average Rating Score") 

# plot 2 graphs - place multiple grobs on a page
grid.arrange(rating_count_per_rate_year,score_by_week, ncol=2)
```

#### F. Fifth model Reg. Movie + User Effect + Time effect 
Time effect along with movie effect and user effect supported by previous analysis. 

We'll create a model that add a time effect to the regularized movie and user joint model. 

We define d_ui as the day for user's u rating of movie i. 

The model; <TODO>

Fit the model;
```{r fit time model} 
fit_time_ave <-  
  train_edx %>% 
  mutate(week = round_date(rate_date, unit = "week")) %>%
  left_join(fit_reg_movie_ave, by='movieId') %>%
  left_join(fit_reg_user_movie_ave, by='userId') %>%
  group_by(week) %>%
  summarize(d_ui=mean(rating-mu-reg_b_i-reg_b_ui))
```
Predict the ratings;
```{r predict time model}
predicted_ratings <- 
  test_edx %>% 
  mutate(week = round_date(rate_date, unit = "week")) %>%
  left_join(fit_reg_movie_ave, by='movieId') %>%
  left_join(fit_reg_user_movie_ave, by='userId') %>%
  left_join(fit_time_ave, by="week") %>%
  mutate(predicted = mu+reg_b_i+reg_b_ui+d_ui) %>%
  pull(predicted)
```
### Model results
```{r model 5 results}
model_5_rmse <- RMSE(true_ratings=test_edx$rating,
                     predicted_ratings=predicted_ratings)

model_5_mse <- MSE(test_edx$rating,reg_predicted_ratings)

#add the results to the table 
model_5_results <- tibble(method = "Reg. Movie + User Effect + Time effect",
                          MSE=model_5_mse, RMSE = model_5_rmse)
model_5_results
```
The residual summary as shown; 
```{r time effect model residual summary, echo=FALSE}
test_edx %>% 
  mutate(week = round_date(rate_date, unit = "week")) %>%
  left_join(fit_reg_movie_ave, by='movieId') %>%
  left_join(fit_reg_user_movie_ave, by='userId') %>%
  left_join(fit_time_ave, by="week") %>%
  mutate(predicted = mu+reg_b_i+reg_b_ui+d_ui,
         reg_squared_errors=(rating-predicted)^2) %>% 
  select(reg_squared_errors) %>% 
  summary()
```
The model MSE distribution   
```{r time effect model MSE distribution, echo=FALSE}
test_edx %>% 
  mutate(week = round_date(rate_date, unit = "week")) %>%
  left_join(fit_reg_movie_ave, by='movieId') %>%
  left_join(fit_reg_user_movie_ave, by='userId') %>%
  left_join(fit_time_ave, by="week") %>%
  mutate(predicted = mu+reg_b_i+reg_b_ui+d_ui,
         se=((rating-predicted)^2)) %>%
  group_by(movieId) %>% 
  summarise(mse=mean(se)) %>% 
  ggplot(aes(mse))+
  geom_histogram(bins=30, color="black")+
  geom_vline(aes(xintercept=mean(mse)),color="red", linetype="dashed", size=0.5)+
  ggtitle("")+ 
  labs(x="Mean squared errors", y="number of movies")
```
The model obtain RMSE= 0.8658609, improvement of 18.31501 from the naive RMSE and just 0.01% improvement from the regularized movie and user effect model. 

The time effect is beraly significant. 

### 13. Genres
Movies are classified to different geners. Some genres are very popular and contain large amount of movies and some are beraly heard.

In addition, Different users tend to favor certain genres over others and target their watching and rating habits toward them. 

The genres column include every gener that aplies to the movie. Some movies fall under several geners as folowing; 
```{r example of the diffrent geners, echo=FALSE}
# example of the diffrent geners
train_edx[20:23,] %>% select (title,genres) 
```
We'll separat the edx train and test sets rows for unique genres.
Movie with more than one genre will split into several rows, each row represent a unique genre. 
```{r }
train_edx_genres <- train_edx %>%  separate_rows(genres, sep="\\|")
test_edx_genres <- test_edx %>%  separate_rows(genres, sep="\\|")
```
The Distribution of the geners by their total ratings and total average score as follow; 
```{r gener dist, echo=FALSE}
# figure 29 # 
train_edx_genres %>% 
  group_by(genres) %>% 
  filter(genres!="(no genres listed)") %>%
  summarize(count = n(),ave_rating=mean(rating)) %>% 
  arrange(desc(count)) %>%
  mutate(percentage=100*count/sum(count)) %>% 
  ggplot(aes(ave_rating,percentage))+
  geom_point()+
  geom_text(aes(label=genres), size=3,  hjust=0,vjust=0)+
  ggtitle("Distribution of movies for each gener")+ 
  labs(x="average rating score", y="percentage of the rating count")
```
There are 19 uniqe genres. 

Drama genre leads with 17% of total ratings and the highst average score. 

The genres with average score over 3.4 stars and on top 20 quantile of total ratings are the foliwing; 
```{r filter genres, echo=FALSE}
train_edx_genres %>% 
  group_by(genres) %>% 
  filter(genres!="(no genres listed)") %>%
  summarize(count_m = round(n()/1000000,2), #number of ratings in millions
            ave_rating=round(mean(rating),2),
            year=release_year[1]) %>% 
  mutate(percentage=round(100*count_m/sum(count_m)),2) %>% 
  filter(ave_rating>=3.4 & count_m>=quantile(count_m, 0.80)) %>% 
  arrange(desc(percentage)) %>%   
  select(genres,count_m,ave_rating, percentage) %>% 
  knitr::kable()
```
We can see that those 4 genres has changed over the years, but in general their ratings respectivly increases until the mid 90's and their average rate score decreases constantly. 
```{r graph geners over the years, echo=FALSE, out.width = '80%'}
# figure 30 #
genres_rating_over_years <- 
  train_edx_genres %>% 
  group_by(genres,release_year) %>% 
  summarize(count_k=n()/1000,     #number of ratings in thousand
            year=release_year[1]) %>%
  filter(genres %in% c("Drama", "Comedy", "Action","Thriller"),
         release_year>="1960") %>%
  ggplot(aes(x =year, y = count_k)) +
  geom_point(aes(color=genres))+
  geom_smooth()

# score over the years
# figure 31 #
genres_score_over_years <- 
  train_edx_genres %>% 
  group_by(genres,release_year) %>% 
  summarize(ave=mean(rating),
            year=release_year[1]) %>%
  filter(genres %in% c("Drama", "Comedy", "Action", "Thriller"),
         release_year>="1960") %>%
  ggplot(aes(x =year, y = ave)) +
  geom_point(aes(color=genres)) + 
  geom_smooth()

# plot 2 graphs - place multiple grobs on a page
plot_grid(genres_rating_over_years,genres_score_over_years, ncol=1, align="v")
```

The analysis shows evidance of genre effect. We'll add the effect to our previous model. 

#### G. Sisth model - Reg. Movie + User Effect + Time Effect + Genres Effect 

We define g_u_i as the genre for user's u rating of movie i

The model; 

Fit the model; 
```{r fit geners model}
fit_genres_ave <-  
  train_edx_genres %>% 
  mutate(week = round_date(rate_date, unit = "week")) %>%
  left_join(fit_reg_movie_ave, by='movieId') %>%
  left_join(fit_reg_user_movie_ave, by='userId') %>%
  left_join(fit_time_ave, by="week") %>%
  group_by(genres) %>%
  summarize(b_g=mean(rating-mu-reg_b_i-reg_b_ui-d_ui))
```

```{r predict geners model ratings}
predicted_ratings <- 
  test_edx_genres %>% 
  mutate(week = round_date(rate_date, unit = "week")) %>%
  left_join(fit_reg_movie_ave, by='movieId') %>%
  left_join(fit_reg_user_movie_ave, by='userId') %>%
  left_join(fit_time_ave, by="week") %>%
  left_join(fit_genres_ave, by='genres') %>% 
  mutate(predicted = mu+reg_b_i+reg_b_ui+d_ui+b_g) %>%
  pull(predicted)
```

```{r model 6 results}
model_6_rmse <- RMSE(true_ratings=test_edx_genres$rating,
                     predicted_ratings=predicted_ratings)

model_6_mse <- MSE(test_edx_genres$rating,predicted_ratings)

#add the results to the table 
model_6_results <- 
  tibble(method = "Reg. Movie + User Effect + Time Effect + Genres Effect",
         MSE=model_6_mse, RMSE = model_6_rmse)
model_6_results
```

plot the mse
```{r model 6 mse plot, echo=FALSE}
# figure 32 #
test_edx_genres %>% mutate(week = round_date(rate_date, unit = "week")) %>%
  left_join(fit_reg_movie_ave, by='movieId') %>%
  left_join(fit_reg_user_movie_ave, by='userId') %>%
  left_join(fit_time_ave, by="week") %>%
  left_join(fit_genres_ave, by='genres') %>% 
  mutate((predicted = mu+reg_b_i+reg_b_ui+d_ui+b_g),
         se=((rating-predicted)^2)) %>% 
  group_by(movieId) %>% 
  summarise(mse=mean(se)) %>% 
  ggplot(aes(mse))+
  geom_histogram(bins=30, color="black")+
  geom_vline(aes(xintercept=mean(mse)),color="red", linetype="dashed", size=0.5)+
  ggtitle("7")+ 
  labs(x="Mean squared errors", y="number of movies")
```

#####################
# test on validation#
#####################

```{r test validation}
test_validation <- 
  validation %>%  
  mutate (rate_date = date(as_datetime(timestamp)),
          release_year =as.numeric(str_extract(title,"(?<=\\()(\\d{4})(?=\\))")),
          title= str_remove(as.character(title), "(\\(\\d{4}\\))")) %>% 
  select(-timestamp) %>%
  separate_rows(genres, sep="\\|")
```

```{r fit final model}
fit_genre_ave <-  
  train_edx_genres %>% 
  mutate(week = round_date(rate_date, unit = "week")) %>%
  left_join(fit_reg_movie_ave, by='movieId') %>%
  left_join(fit_reg_user_movie_ave, by='userId') %>%
  left_join(fit_time_ave, by="week") %>%
  group_by(genres) %>%
  summarize(b_g=mean(rating-mu-reg_b_i-reg_b_ui-d_ui))
```

```{r predict ratings validation set }
predicted_ratings <- 
  test_validation %>% 
  mutate(week = round_date(rate_date, unit = "week")) %>%
  left_join(fit_reg_movie_ave, by='movieId') %>%
  left_join(fit_reg_user_movie_ave, by='userId') %>%
  left_join(fit_time_ave, by="week") %>%
  left_join(fit_genres_ave, by='genres') %>% 
  mutate(predicted = mu+reg_b_i+reg_b_ui+d_ui+b_g) %>%
  pull(predicted)
```

```{r final model results }
model_final_rmse <- RMSE(true_ratings=test_validation$rating,
                         predicted_ratings=predicted_ratings)
model_final_mse <- MSE(test_validation$rating,predicted_ratings)

#add the results to the table 
model_final_results <- 
  tibble(method = "final",
         MSE=model_final_mse, RMSE = model_final_rmse)
model_final_results
```

```{r}
### Models results table
rbind(naive_model_results,
      model_1_results, 
      model_1_1_results,
      model_2_results, 
      model_2_1_results,
      model_3_results, 
      model_3_1_results,
      model_4_results, 
      model_5_results,
      model_6_results, 
      model_final_results) %>%
  arrange(MSE)
```



